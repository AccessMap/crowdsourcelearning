{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a4ceeb72b1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named sklearn"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, linear_model, preprocessing\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score\n",
    "from __future__ import division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./learndata-latest.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crowd_labels = pd.read_csv('./crowdsource-20160208.csv')\n",
    "crowd_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data2 = pd.DataFrame()\n",
    "\n",
    "True_disagree = 0. \n",
    "False_disagree = 0. \n",
    "\n",
    "NoConn = sum(raw_data['connected'])\n",
    "NotConn = len(raw_data) - NoConn + 0. \n",
    "\n",
    "for i in range(0,len(crowd_labels)):\n",
    "    temp = raw_data[raw_data['id_i']==crowd_labels['swi_id'][i]]\n",
    "    temp2 = temp[temp['id_j']==crowd_labels['swj_id'][i]]\n",
    "    raw_data2 = raw_data2.append(temp2,ignore_index=True)\n",
    "    \n",
    "\n",
    "    if (i%1000==0):\n",
    "        print i\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data2.head()\n",
    "NoDis = sum(raw_data2['connected']!=crowd_labels['connected'])\n",
    "print NoDis\n",
    "raw_data2['connected']=crowd_labels['connected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove features that we shouldn't learn (encoded geometries and sidewalk ID numbers)\n",
    "near_line = raw_data2['near_line']  # Save for later\n",
    "del raw_data2['near_line']\n",
    "del raw_data2['id_i']\n",
    "del raw_data2['id_j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Binarizes categorical variables \n",
    "# (e.g. if 3 categories, makes 3 cols with 1s and 0s)\n",
    "# X = pd.get_dummies(raw_data)  \n",
    "\n",
    "# Turn categorical variables into integer labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "raw_data2['curbtype_i'] = label_encoder.fit_transform(raw_data2['curbtype_i'])\n",
    "raw_data2['curbtype_j'] = label_encoder.fit_transform(raw_data2['curbtype_j'])\n",
    "raw_data2['side_i'] = label_encoder.fit_transform(raw_data2['side_i'])\n",
    "raw_data2['side_j'] = label_encoder.fit_transform(raw_data2['side_j'])\n",
    "raw_data2['surftype_i'] = label_encoder.fit_transform(raw_data2['surftype_i'])\n",
    "raw_data2['surftype_j'] = label_encoder.fit_transform(raw_data2['surftype_j'])\n",
    "raw_data2['intersects'] = label_encoder.fit_transform(raw_data2['intersects'])\n",
    "\n",
    "X = raw_data2\n",
    "\n",
    "X['same_curbtype'] = (X['curbtype_i'] == X['curbtype_j']).astype(int)\n",
    "X['same_surftype'] = (X['surftype_i'] == X['surftype_j']).astype(int)\n",
    "X['same_block'] = (X['bid_i'] == X['bid_j']).astype(int)\n",
    "X['same_side'] = (X['side_i'] == X['side_j']).astype(int)\n",
    "\n",
    "# TODO: There's probably more features we can generate with these two lengths\n",
    "X['length_diff'] = abs(X['length_i'] - X['length_j'])\n",
    "X['sw_width_diff'] = abs(X['sw_width_i'] - X['sw_width_j'])\n",
    "\n",
    "y = X['connected']\n",
    "X = X.drop('connected', 1)\n",
    "X = X.drop('curbtype_i', 1)\n",
    "X = X.drop('curbtype_j', 1)\n",
    "X = X.drop('surftype_i', 1)\n",
    "X = X.drop('surftype_j', 1)\n",
    "\n",
    "X['near_angle'] = abs(X['near_angle'])\n",
    "\n",
    "del X['bid_i']  # This has NaN and will cause errors in sklearn\n",
    "del X['bid_j']\n",
    "\n",
    "del X['side_i']\n",
    "del X['side_j']\n",
    "del X['length_i']\n",
    "del X['length_j']\n",
    "del X['sw_width_i']\n",
    "del X['sw_width_j']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scaling appropriate features by subtracting mean and scaling to unit variance\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X['near_distance'] = scaler.fit_transform(X['near_distance'])\n",
    "X['length_diff'] = scaler.fit_transform(X['length_diff'])\n",
    "X['sw_width_diff'] = scaler.fit_transform(X['sw_width_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.5, random_state=6883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#SVM with a RBF kernel \n",
    "svmR = svm.SVC(kernel='rbf')\n",
    "svmR.fit(X_train, y_train)\n",
    "print svmR.score(X_test, y_test)\n",
    "svmR_pred = svmR.predict(X_test)\n",
    "print precision_score(y_test, svmR_pred)\n",
    "print recall_score(y_test, svmR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pred = svmR.predict(X)\n",
    "\n",
    "X_out = X.copy()\n",
    "X_acc = X_pred == y\n",
    "\n",
    "true_positives = X_out[np.logical_and(X_pred, X_acc)]\n",
    "false_positives = X_out[np.logical_and(X_pred, np.logical_not(X_acc))]\n",
    "true_negatives = X_out[np.logical_and(np.logical_not(X_pred), X_acc)]\n",
    "false_negatives = X_out[np.logical_and(np.logical_not(X_pred), np.logical_not(X_acc))]\n",
    "\n",
    "print true_positives.shape\n",
    "print true_negatives.shape\n",
    "print false_positives.shape\n",
    "print false_negatives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export errors as geojson for visualizing on github\n",
    "import json\n",
    "from shapely import wkt\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "geojson = {}\n",
    "geojson['type'] = 'FeatureCollection'\n",
    "geojson['features'] = []\n",
    "\n",
    "for i in range(len(X_pred)):\n",
    "    if not X_acc[i]:\n",
    "        feature = {}\n",
    "        feature['type'] = 'Feature'\n",
    "        geom = wkt.loads(near_line[i])\n",
    "        feature['geometry'] = mapping(geom)\n",
    "        if X_pred[i]:\n",
    "            properties = {'predicted': 1,\n",
    "                          'type': 'false positive',\n",
    "                          'stroke': '#FC0000',\n",
    "                          'stroke-width': 5}\n",
    "        else:\n",
    "            properties = {'predicted': 0,\n",
    "                          'type': 'false negative',\n",
    "                          'stroke': '#093CA8',\n",
    "                          'stroke-width': 5}\n",
    "        feature['properties'] = properties\n",
    "        geojson['features'].append(feature)\n",
    "        \n",
    "with open('./learndata-errorsCrowd.geojson', 'w') as f:\n",
    "    json.dump(geojson, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data3 = pd.DataFrame()\n",
    "\n",
    "True_disagree = 0. \n",
    "False_disagree = 0. \n",
    "\n",
    "NoConn = sum(raw_data['connected'])\n",
    "NotConn = len(raw_data) - NoConn + 0. \n",
    "\n",
    "for i in range(0,len(crowd_labels)):\n",
    "    temp = raw_data[raw_data['id_i']==crowd_labels['swi_id'][i]]\n",
    "    temp2 = temp[temp['id_j']==crowd_labels['swj_id'][i]]\n",
    "    raw_data3 = raw_data3.append(temp2,ignore_index=True)\n",
    "    \n",
    "\n",
    "    if (i%1000==0):\n",
    "        print i\n",
    "\n",
    "y3 = raw_data3['connected']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pred = y3\n",
    "\n",
    "X_out = X.copy()\n",
    "X_acc = X_pred == y\n",
    "\n",
    "true_positives = X_out[np.logical_and(X_pred, X_acc)]\n",
    "false_positives = X_out[np.logical_and(X_pred, np.logical_not(X_acc))]\n",
    "true_negatives = X_out[np.logical_and(np.logical_not(X_pred), X_acc)]\n",
    "false_negatives = X_out[np.logical_and(np.logical_not(X_pred), np.logical_not(X_acc))]\n",
    "\n",
    "print true_positives.shape\n",
    "print true_negatives.shape\n",
    "print false_positives.shape\n",
    "print false_negatives.shape\n",
    "\n",
    "\n",
    "geojson = {}\n",
    "geojson['type'] = 'FeatureCollection'\n",
    "geojson['features'] = []\n",
    "\n",
    "for i in range(len(X_pred)):\n",
    "    if not X_acc[i]:\n",
    "        feature = {}\n",
    "        feature['type'] = 'Feature'\n",
    "        geom = wkt.loads(near_line[i])\n",
    "        feature['geometry'] = mapping(geom)\n",
    "        if X_pred[i]:\n",
    "            properties = {'predicted': 1,\n",
    "                          'type': 'false positive',\n",
    "                          'stroke': '#FC0000',\n",
    "                          'stroke-width': 5}\n",
    "        else:\n",
    "            properties = {'predicted': 0,\n",
    "                          'type': 'false negative',\n",
    "                          'stroke': '#093CA8',\n",
    "                          'stroke-width': 5}\n",
    "        feature['properties'] = properties\n",
    "        geojson['features'].append(feature)\n",
    "        \n",
    "with open('./learndata-errorsHeuristic_onCrowd.geojson', 'w') as f:\n",
    "    json.dump(geojson, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
