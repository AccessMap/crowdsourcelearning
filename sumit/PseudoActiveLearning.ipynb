{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, linear_model, preprocessing\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score\n",
    "from __future__ import division\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./sw_classifications_20160526-afterdedupe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique sidewalk pair labels: 11132\n",
      "Number of labels with more than 3 responses: 862\n",
      "Number of labels with 2 responses: 976\n"
     ]
    }
   ],
   "source": [
    "gb = data.groupby(['swi_id', 'swj_id'])\n",
    "groups = gb.groups\n",
    "more_3 = {key: value for key, value in groups.iteritems() if len(value) >= 3}\n",
    "more_2 = {key: value for key, value in groups.iteritems() if len(value) >= 2}\n",
    "print 'Number of unique sidewalk pair labels: {}'.format(len(groups))\n",
    "print 'Number of labels with more than 3 responses: {}'.format(len(more_3))\n",
    "print 'Number of labels with 2 responses: {}'.format(len(more_2)-len(more_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_fraction(sw_labelset):\n",
    "    '''\n",
    "    :param sw_labelset: List of 't' (True) or 'f' (False) labels for a single sidewalk pair.\n",
    "    :type sw_labelset: list\n",
    "    \n",
    "    '''\n",
    "    tf = data.iloc[sw_labelset, :]['connected']\n",
    "    fraction_t = sum([1 for label in tf if label == 't']) / float(len(sw_labelset))\n",
    "    \n",
    "    return fraction_t\n",
    "\n",
    "def decide_label(fraction):\n",
    "    '''Decide how to label a given sidewalk pair given multiple responses.'''\n",
    "    # If majority is 't', choose 't'\n",
    "    if fraction > 0.5:\n",
    "        return 't'\n",
    "    # If majority is 'f', choose 'f'\n",
    "    elif fraction < 0.5:\n",
    "        return 'f'\n",
    "    # If even split, ignore entirely for now\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swi_id</th>\n",
       "      <th>swj_id</th>\n",
       "      <th>connected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>325902</td>\n",
       "      <td>326474</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>326184</td>\n",
       "      <td>326185</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2548</th>\n",
       "      <td>297773</td>\n",
       "      <td>303110</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>322238</td>\n",
       "      <td>330093</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10184</th>\n",
       "      <td>319771</td>\n",
       "      <td>320091</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       swi_id  swj_id connected\n",
       "6276   325902  326474         f\n",
       "736    326184  326185         f\n",
       "2548   297773  303110         f\n",
       "1925   322238  330093         f\n",
       "10184  319771  320091         t"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractions2 = []\n",
    "labels2 = []\n",
    "for key, value in more_2.iteritems():\n",
    "    fraction = label_fraction(value)\n",
    "    label = decide_label(fraction)\n",
    "    if label is not None:\n",
    "        newrow = data.ix[value[0],['swi_id', 'swj_id', 'connected']]\n",
    "        newrow['connected'] = label\n",
    "        labels2.append(newrow)\n",
    "        fractions2.append(fraction)\n",
    "\n",
    "labels2 = pd.DataFrame(labels2)\n",
    "labels2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>swi_id</th>\n",
       "      <th>swj_id</th>\n",
       "      <th>connected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>325902</td>\n",
       "      <td>326474</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>329341</td>\n",
       "      <td>329342</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6772</th>\n",
       "      <td>302721</td>\n",
       "      <td>302737</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>326184</td>\n",
       "      <td>326185</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7681</th>\n",
       "      <td>328733</td>\n",
       "      <td>328748</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      swi_id  swj_id connected\n",
       "6276  325902  326474         f\n",
       "1567  329341  329342         f\n",
       "6772  302721  302737         f\n",
       "736   326184  326185         f\n",
       "7681  328733  328748         f"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fractions3 = []\n",
    "labels3 = []\n",
    "for key, value in more_3.iteritems():\n",
    "    fraction = label_fraction(value)\n",
    "    label = decide_label(fraction)\n",
    "    if label is not None:\n",
    "        newrow = data.ix[value[0],['swi_id', 'swj_id', 'connected']]\n",
    "        newrow['connected'] = label\n",
    "        labels3.append(newrow)\n",
    "        fractions3.append(fraction)\n",
    "\n",
    "labels3 = pd.DataFrame(labels3)\n",
    "labels3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./learndata-latest.csv')\n",
    "raw_data.head()\n",
    "crowd_labels = labels2\n",
    "crowd_labels.head()\n",
    "raw_data2 = pd.DataFrame()\n",
    "\n",
    "True_disagree = 0. \n",
    "False_disagree = 0. \n",
    "\n",
    "NoConn = sum(raw_data['connected'])\n",
    "NotConn = len(raw_data) - NoConn + 0. \n",
    "\n",
    "crowd_labels = crowd_labels.reset_index()\n",
    "\n",
    "for i in range(0,len(crowd_labels)):\n",
    "    temp = raw_data[raw_data['id_i']==crowd_labels['swi_id'][i]]\n",
    "    temp2 = temp[temp['id_j']==crowd_labels['swj_id'][i]]\n",
    "    raw_data2 = raw_data2.append(temp2,ignore_index=True)\n",
    "    \n",
    "\n",
    "    if (i%1000==0):\n",
    "        print i\n",
    "temp = pd.DataFrame({'Hlab' : raw_data2['connected']})\n",
    "raw_data2 = pd.concat([temp,raw_data2],axis=1)\n",
    "raw_data2['connected']=crowd_labels['connected']\n",
    "raw_data2.head()\n",
    "\n",
    "# Remove features that we shouldn't learn (encoded geometries and sidewalk ID numbers)\n",
    "near_line = raw_data2['near_line']  # Save for later\n",
    "del raw_data2['near_line']\n",
    "del raw_data2['id_i']\n",
    "del raw_data2['id_j']\n",
    "\n",
    "# Binarizes categorical variables \n",
    "# (e.g. if 3 categories, makes 3 cols with 1s and 0s)\n",
    "# X = pd.get_dummies(raw_data)  \n",
    "\n",
    "# Turn categorical variables into integer labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "raw_data2['curbtype_i'] = label_encoder.fit_transform(raw_data2['curbtype_i'])\n",
    "raw_data2['curbtype_j'] = label_encoder.fit_transform(raw_data2['curbtype_j'])\n",
    "raw_data2['side_i'] = label_encoder.fit_transform(raw_data2['side_i'])\n",
    "raw_data2['side_j'] = label_encoder.fit_transform(raw_data2['side_j'])\n",
    "raw_data2['surftype_i'] = label_encoder.fit_transform(raw_data2['surftype_i'])\n",
    "raw_data2['surftype_j'] = label_encoder.fit_transform(raw_data2['surftype_j'])\n",
    "raw_data2['intersects'] = label_encoder.fit_transform(raw_data2['intersects'])\n",
    "\n",
    "X = raw_data2\n",
    "\n",
    "X['same_curbtype'] = (X['curbtype_i'] == X['curbtype_j']).astype(int)\n",
    "X['same_surftype'] = (X['surftype_i'] == X['surftype_j']).astype(int)\n",
    "X['same_block'] = (X['bid_i'] == X['bid_j']).astype(int)\n",
    "X['same_side'] = (X['side_i'] == X['side_j']).astype(int)\n",
    "\n",
    "# TODO: There's probably more features we can generate with these two lengths\n",
    "X['length_diff'] = abs(X['length_i'] - X['length_j'])\n",
    "X['sw_width_diff'] = abs(X['sw_width_i'] - X['sw_width_j'])\n",
    "\n",
    "y = X['connected']\n",
    "X = X.drop('connected', 1)\n",
    "X = X.drop('curbtype_i', 1)\n",
    "X = X.drop('curbtype_j', 1)\n",
    "X = X.drop('surftype_i', 1)\n",
    "X = X.drop('surftype_j', 1)\n",
    "\n",
    "X['near_angle'] = abs(X['near_angle'])\n",
    "\n",
    "del X['bid_i']  # This has NaN and will cause errors in sklearn\n",
    "del X['bid_j']\n",
    "\n",
    "del X['side_i']\n",
    "del X['side_j']\n",
    "del X['length_i']\n",
    "del X['length_j']\n",
    "del X['sw_width_i']\n",
    "del X['sw_width_j']\n",
    "\n",
    "X.head()\n",
    "\n",
    "# Scaling appropriate features by subtracting mean and scaling to unit variance\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X['near_distance'] = scaler.fit_transform(X['near_distance'])\n",
    "X['length_diff'] = scaler.fit_transform(X['length_diff'])\n",
    "X['sw_width_diff'] = scaler.fit_transform(X['sw_width_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.5, random_state=6883)\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(2)\n",
    "Xp = poly.fit_transform(X)\n",
    "Xp_train, Xp_test, yp_train, yp_test = cross_validation.train_test_split(Xp, y, test_size=0.5, random_state=6883)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966555183946\n",
      "0.983146067416\n",
      "0.866336633663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\svm\\base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "svmc = svm.SVC(C=1, kernel = 'linear',probability=False)\n",
    "svmc.fit(Xp_train, y_train)\n",
    "print svmc.score(Xp_test, yp_test)\n",
    "svmc_pred = svmc.predict(Xp_test)\n",
    "print precision_score(yp_test, svmc_pred)\n",
    "print recall_score(yp_test, svmc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966555183946\n",
      "Precision score (what fraction of predicted connections are true): 0.967391304348\n",
      "Recall score (what fraction of connections were found?): 0.881188118812\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d89790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logisticp = linear_model.LogisticRegression(penalty='l1', C=0.001)\n",
    "logisticp.fit(Xp_train, yp_train)\n",
    "print logisticp.score(Xp_test, yp_test)\n",
    "yp_pred = logisticp.predict(Xp_test)\n",
    "Prob = logisticp.predict_proba(Xp_test)\n",
    "precisionp, recallp, thresholdsp = precision_recall_curve(yp_test, yp_pred)\n",
    "print \"Precision score (what fraction of predicted connections are true): {}\".format(precision_score(yp_test, yp_pred))\n",
    "print \"Recall score (what fraction of connections were found?): {}\".format(recall_score(yp_test, yp_pred))\n",
    "\n",
    "plt.plot(recallp, precisionp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get probabilities for each class \n",
    "\n",
    "LowClass1 = Prob[:,0]<0.99\n",
    "LowClass2 = Prob[:,1]<0.99\n",
    "Ambig = (LowClass1==LowClass2)\n",
    "HighClass1 = Prob[:,0]>0.99\n",
    "HighClass2 = Prob[:,1]>0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991967871486\n",
      "1.0\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "#calculate efficiency in non-ambiguous\n",
    "NonAmbigIn = np.logical_or(HighClass1, HighClass2)\n",
    "print logisticp.score(Xp_test[NonAmbigIn], yp_test[NonAmbigIn])\n",
    "l_pred = logisticp.predict(Xp_test[NonAmbigIn])\n",
    "print precision_score(yp_test[NonAmbigIn], l_pred)\n",
    "print recall_score(yp_test[NonAmbigIn], l_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84\n",
      "0.914285714286\n",
      "0.780487804878\n"
     ]
    }
   ],
   "source": [
    "#calculate efficiency ambiguous\n",
    "print logisticp.score(Xp_test[Ambig], y_test[Ambig])\n",
    "l_pred = logisticp.predict(Xp_test[Ambig])\n",
    "print precision_score(y_test[Ambig], l_pred)\n",
    "print recall_score(y_test[Ambig], l_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40594059]\n",
      "[ 0.59405941]\n"
     ]
    }
   ],
   "source": [
    "#see fraction of ambiguous 1's \n",
    "Ambig1 = sum(yp_test[Ambig])/sum(yp_test)\n",
    "print Ambig1\n",
    "#fraction of unambiguous 1's \n",
    "print 1- Ambig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yp_test[Ambig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\preprocessing\\data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./learndata-latest.csv')\n",
    "raw_data.head()\n",
    "crowd_labels = labels2\n",
    "crowd_labels = pd.read_csv('./crowdsource-20160208.csv')\n",
    "crowd_labels.head()\n",
    "raw_data2 = pd.DataFrame()\n",
    "\n",
    "True_disagree = 0. \n",
    "False_disagree = 0. \n",
    "\n",
    "NoConn = sum(raw_data['connected'])\n",
    "NotConn = len(raw_data) - NoConn + 0. \n",
    "\n",
    "crowd_labels = crowd_labels.reset_index()\n",
    "\n",
    "for i in range(0,len(crowd_labels)):\n",
    "    temp = raw_data[raw_data['id_i']==crowd_labels['swi_id'][i]]\n",
    "    temp2 = temp[temp['id_j']==crowd_labels['swj_id'][i]]\n",
    "    raw_data2 = raw_data2.append(temp2,ignore_index=True)\n",
    "    \n",
    "\n",
    "    if (i%1000==0):\n",
    "        print i\n",
    "temp = pd.DataFrame({'Hlab' : raw_data2['connected']})\n",
    "raw_data2 = pd.concat([temp,raw_data2],axis=1)\n",
    "raw_data2['connected']=crowd_labels['connected']\n",
    "raw_data2.head()\n",
    "\n",
    "# Remove features that we shouldn't learn (encoded geometries and sidewalk ID numbers)\n",
    "near_line = raw_data2['near_line']  # Save for later\n",
    "del raw_data2['near_line']\n",
    "del raw_data2['id_i']\n",
    "del raw_data2['id_j']\n",
    "\n",
    "# Binarizes categorical variables \n",
    "# (e.g. if 3 categories, makes 3 cols with 1s and 0s)\n",
    "# X = pd.get_dummies(raw_data)  \n",
    "\n",
    "# Turn categorical variables into integer labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "raw_data2['curbtype_i'] = label_encoder.fit_transform(raw_data2['curbtype_i'])\n",
    "raw_data2['curbtype_j'] = label_encoder.fit_transform(raw_data2['curbtype_j'])\n",
    "raw_data2['side_i'] = label_encoder.fit_transform(raw_data2['side_i'])\n",
    "raw_data2['side_j'] = label_encoder.fit_transform(raw_data2['side_j'])\n",
    "raw_data2['surftype_i'] = label_encoder.fit_transform(raw_data2['surftype_i'])\n",
    "raw_data2['surftype_j'] = label_encoder.fit_transform(raw_data2['surftype_j'])\n",
    "raw_data2['intersects'] = label_encoder.fit_transform(raw_data2['intersects'])\n",
    "\n",
    "X2 = raw_data2\n",
    "\n",
    "X2['same_curbtype'] = (X2['curbtype_i'] == X2['curbtype_j']).astype(int)\n",
    "X2['same_surftype'] = (X2['surftype_i'] == X2['surftype_j']).astype(int)\n",
    "X2['same_block'] = (X2['bid_i'] == X2['bid_j']).astype(int)\n",
    "X2['same_side'] = (X2['side_i'] == X2['side_j']).astype(int)\n",
    "\n",
    "# TODO: There's probably more features we can generate with these two lengths\n",
    "X2['length_diff'] = abs(X2['length_i'] - X2['length_j'])\n",
    "X2['sw_width_diff'] = abs(X2['sw_width_i'] - X2['sw_width_j'])\n",
    "\n",
    "y2 = X2['connected']\n",
    "X2 = X2.drop('connected', 1)\n",
    "X2 = X2.drop('curbtype_i', 1)\n",
    "X2 = X2.drop('curbtype_j', 1)\n",
    "X2 = X2.drop('surftype_i', 1)\n",
    "X2 = X2.drop('surftype_j', 1)\n",
    "\n",
    "X2['near_angle'] = abs(X2['near_angle'])\n",
    "\n",
    "del X2['bid_i']  # This has NaN and will cause errors in sklearn\n",
    "del X2['bid_j']\n",
    "\n",
    "del X2['side_i']\n",
    "del X2['side_j']\n",
    "del X2['length_i']\n",
    "del X2['length_j']\n",
    "del X2['sw_width_i']\n",
    "del X2['sw_width_j']\n",
    "\n",
    "X2.head()\n",
    "\n",
    "# Scaling appropriate features by subtracting mean and scaling to unit variance\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X2['near_distance'] = scaler.fit_transform(X2['near_distance'])\n",
    "X2['length_diff'] = scaler.fit_transform(X2['length_diff'])\n",
    "X2['sw_width_diff'] = scaler.fit_transform(X2['sw_width_diff'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953483956712\n",
      "Precision score (what fraction of predicted connections are true): 0.891420911528\n",
      "Recall score (what fraction of connections were found?): 0.889830508475\n"
     ]
    }
   ],
   "source": [
    "#identify ambiguous labels from previous model \n",
    "Xp2 = poly.fit_transform(X2)\n",
    "Xp2_train, Xp2_test, yp2_train, yp2_test = cross_validation.train_test_split(Xp2, y2, test_size=0.01, random_state=6883)\n",
    "\n",
    "yp2_pred = logisticp.predict(Xp2_train)\n",
    "Prob2 = logisticp.predict_proba(Xp2_train)\n",
    "precisionp, recallp, thresholdsp = precision_recall_curve(yp2_train, yp2_pred)\n",
    "print logisticp.score(Xp2_train, yp2_train)\n",
    "print \"Precision score (what fraction of predicted connections are true): {}\".format(precision_score(yp2_train, yp2_pred))\n",
    "print \"Recall score (what fraction of connections were found?): {}\".format(recall_score(yp2_train, yp2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get probabilities for each class \n",
    "\n",
    "LowClass1 = Prob2[:,0]<0.99\n",
    "LowClass2 = Prob2[:,1]<0.99\n",
    "Ambig = (LowClass1==LowClass2)\n",
    "HighClass1 = Prob2[:,0]>0.99\n",
    "HighClass2 = Prob2[:,1]>0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xp_ambig = Xp2_train[Ambig]\n",
    "yp_ambig = yp2_train[Ambig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yp_ambig = np.reshape(yp_ambig,(len(yp_ambig),1))\n",
    "yp_train = np.reshape(yp_train,(len(yp_train),1))\n",
    "Xp_ambig = np.vstack((Xp_ambig,Xp_train))\n",
    "yp_ambig = np.vstack((yp_ambig,yp_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xp3_train, bla, yp3_train, bla2 = cross_validation.train_test_split(Xp_ambig, yp_ambig, test_size=0.01, random_state=6883)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967670011148\n",
      "Precision score (what fraction of predicted connections are true): 0.977900552486\n",
      "Recall score (what fraction of connections were found?): 0.876237623762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#identify ambiguous labels from previous model \n",
    "logisticp2 = linear_model.LogisticRegression(penalty='l1', C=0.001)\n",
    "logisticp2.fit(Xp3_train, yp3_train)\n",
    "yp2_pred = logisticp2.predict(Xp_test)\n",
    "Prob3 = logisticp2.predict_proba(Xp_test)\n",
    "precisionp, recallp, thresholdsp = precision_recall_curve(yp_test, yp2_pred)\n",
    "print logisticp2.score(Xp_test, yp_test)\n",
    "print \"Precision score (what fraction of predicted connections are true): {}\".format(precision_score(yp_test, yp2_pred))\n",
    "print \"Recall score (what fraction of connections were found?): {}\".format(recall_score(yp_test, yp2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LowClass1 = Prob3[:,0]<0.99\n",
    "LowClass2 = Prob3[:,1]<0.99\n",
    "Ambig = (LowClass1==LowClass2)\n",
    "HighClass1 = Prob3[:,0]>0.99\n",
    "HighClass2 = Prob3[:,1]>0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42574257]\n",
      "[ 0.57425743]\n"
     ]
    }
   ],
   "source": [
    "#see fraction of ambiguous 1's \n",
    "AmbigL = sum(yp_test[Ambig])/sum(yp_test)\n",
    "print AmbigL\n",
    "#fraction of unambiguous 1's \n",
    "print 1- AmbigL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yp_test[Ambig])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994350282486\n",
      "1.0\n",
      "0.965517241379\n"
     ]
    }
   ],
   "source": [
    "#calculate efficiency in non-ambiguous\n",
    "NonAmbigIn = np.logical_or(HighClass1, HighClass2)\n",
    "print logisticp2.score(Xp_test[NonAmbigIn], yp_test[NonAmbigIn])\n",
    "l_pred = logisticp2.predict(Xp_test[NonAmbigIn])\n",
    "print precision_score(yp_test[NonAmbigIn], l_pred)\n",
    "print recall_score(yp_test[NonAmbigIn], l_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867724867725\n",
      "0.942028985507\n",
      "0.755813953488\n"
     ]
    }
   ],
   "source": [
    "#calculate efficiency ambiguous\n",
    "print logisticp2.score(Xp_test[Ambig], yp_test[Ambig])\n",
    "l_pred = logisticp2.predict(Xp_test[Ambig])\n",
    "print precision_score(yp_test[Ambig], l_pred)\n",
    "print recall_score(yp_test[Ambig], l_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3546, 1)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp3_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getAccuracy(Xp,y,Xp2,y2):\n",
    "    #identify train test split on high confidence data and train model \n",
    "    Xp_train, Xp_test, yp_train, yp_test = cross_validation.train_test_split(Xp, y, test_size=0.5)\n",
    "    logisticp = linear_model.LogisticRegression(penalty='l1', C=0.01)\n",
    "    logisticp.fit(Xp_train, yp_train)\n",
    "    yp_pred = logisticp.predict(Xp_test)\n",
    "    Prob = logisticp.predict_proba(Xp_test)\n",
    "    Score1 = logisticp.score(Xp_test, yp_test)\n",
    "    Prec1 = precision_score(yp_test, yp_pred)\n",
    "    Rec1 = recall_score(yp_test, yp_pred)\n",
    "            \n",
    "    #identify accuracy on ambiguous and non-ambi labels \n",
    "    LowClass1 = Prob[:,0]<0.99\n",
    "    LowClass2 = Prob[:,1]<0.99\n",
    "    Ambig = (LowClass1==LowClass2)\n",
    "    HighClass1 = Prob[:,0]>0.99\n",
    "    HighClass2 = Prob[:,1]>0.99\n",
    "            \n",
    "    #identify accuracy on non-ambi labels\n",
    "    NonAmbigIn = np.logical_or(HighClass1, HighClass2)\n",
    "    Score1_NA = logisticp.score(Xp_test[NonAmbigIn], yp_test[NonAmbigIn])\n",
    "    l_pred = logisticp.predict(Xp_test[NonAmbigIn])\n",
    "    Prec1_NA = precision_score(yp_test[NonAmbigIn], l_pred)\n",
    "    Rec1_NA = recall_score(yp_test[NonAmbigIn], l_pred)\n",
    "            \n",
    "    #identify accuracy on ambig labels\n",
    "    Score1_A = logisticp.score(Xp_test[Ambig], yp_test[Ambig])\n",
    "    l_pred = logisticp.predict(Xp_test[Ambig])\n",
    "    Prec1_A = precision_score(yp_test[Ambig], l_pred)\n",
    "    Rec1_A = recall_score(yp_test[Ambig], l_pred)\n",
    "\n",
    "    #Identify accuracies for single label data\n",
    "    Xp2_train, Xp2_test, yp2_train, yp2_test = cross_validation.train_test_split(Xp2, y2, test_size=0.01)\n",
    "    yp2_pred = logisticp.predict(Xp2_train)\n",
    "    Prob2 = logisticp.predict_proba(Xp2_train)\n",
    "    Score2 = logisticp.score(Xp2_train, yp2_train)\n",
    "    Prec2 = precision_score(yp2_train, yp2_pred)\n",
    "    Rec2 = recall_score(yp2_train, yp2_pred)\n",
    "    \n",
    "    #identify ambiguous points \n",
    "    LowClass1 = Prob2[:,0]<0.99\n",
    "    LowClass2 = Prob2[:,1]<0.99\n",
    "    Ambig2 = (LowClass1==LowClass2)\n",
    "    HighClass1 = Prob2[:,0]>0.99\n",
    "    HighClass2 = Prob2[:,1]>0.99\n",
    "    \n",
    "    #identifies ambiguous labels on singly label data\n",
    "    Xp_ambig = Xp2_train[Ambig2]\n",
    "    yp_ambig = yp2_train[Ambig2]\n",
    "            \n",
    "    #augment these to original training set \n",
    "    yp_ambig = np.reshape(yp_ambig,(len(yp_ambig),1))\n",
    "    yp_train = np.reshape(yp_train,(len(yp_train),1))\n",
    "    Xp_ambig = np.vstack((Xp_ambig,Xp_train))\n",
    "    yp_ambig = np.vstack((yp_ambig,yp_train))\n",
    "            \n",
    "    #Re-identify accuracies for original test data\n",
    "    Xp3_train, bla, yp3_train, bla2 = cross_validation.train_test_split(Xp_ambig, yp_ambig, test_size=0.01)\n",
    "    logisticp2 = linear_model.LogisticRegression(penalty='l1', C=0.01)\n",
    "    logisticp2.fit(Xp3_train, yp3_train)\n",
    "    yp3_pred = logisticp2.predict(Xp_test)\n",
    "    Prob3 = logisticp2.predict_proba(Xp_test)\n",
    "    Score3 = logisticp2.score(Xp_test, yp_test)\n",
    "    Prec3 = precision_score(yp_test, yp3_pred)\n",
    "    Rec3 = recall_score(yp_test, yp3_pred)\n",
    "\n",
    "\n",
    "    #Re-identify accuracies for non-ambiguous test data         \n",
    "    Score3_NA = logisticp2.score(Xp_test[NonAmbigIn], yp_test[NonAmbigIn])\n",
    "    l_pred3NA = logisticp2.predict(Xp_test[NonAmbigIn])\n",
    "    Prec3_NA = precision_score(yp_test[NonAmbigIn], l_pred3NA)\n",
    "    Rec3_NA = recall_score(yp_test[NonAmbigIn], l_pred3NA)\n",
    "            \n",
    "    #Re-identify accuracies for non-ambiguous test data         \n",
    "    Score3_A = logisticp2.score(Xp_test[Ambig], yp_test[Ambig])\n",
    "    l_pred3A = logisticp2.predict(Xp_test[Ambig])\n",
    "    Prec3_A = precision_score(yp_test[Ambig], l_pred3A)\n",
    "    Rec3_A = recall_score(yp_test[Ambig], l_pred3A)\n",
    "\n",
    "    RetData = {'Score1':Score1,'Prec1':Prec1,'Rec1':Rec1, 'Score1_NA':Score1, 'Prec1_NA':Prec1_NA,'Rec1_NA':Rec1_NA, \\\n",
    "               'Score1_A':Score1_A,'Prec1_A':Prec1_A,'Rec1_A':Rec1_A, \\\n",
    "              'Score3_NA':Score3_NA,'Prec3_NA':Prec3_NA,'Score3_A':Score3_A,'Rec3_NA':Rec3_NA, 'Prec3_A':Prec3_A, \\\n",
    "               'Rec3_A':Rec3_A,'Score3':Score3,'Prec3':Prec3,'Rec3':Rec3, 'Prec2':Prec2,'Rec2':Rec2,'Score2':Score2}\n",
    "    return RetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\python27\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#identifies different accuracies for multiple permutations \n",
    "\n",
    "NoSamples = 25 \n",
    "Score1 = np.zeros((NoSamples,1)) \n",
    "Prec1 = np.zeros((NoSamples,1))\n",
    "Rec1 = np.zeros((NoSamples,1))\n",
    "Score1_A = np.zeros((NoSamples,1)) \n",
    "Prec1_A = np.zeros((NoSamples,1))\n",
    "Rec1_A = np.zeros((NoSamples,1))\n",
    "Score1_NA = np.zeros((NoSamples,1)) \n",
    "Prec1_NA = np.zeros((NoSamples,1))\n",
    "Rec1_NA = np.zeros((NoSamples,1))\n",
    "Score2 = np.zeros((NoSamples,1)) \n",
    "Prec2 = np.zeros((NoSamples,1))\n",
    "Rec2 = np.zeros((NoSamples,1))\n",
    "Score3 = np.zeros((NoSamples,1)) \n",
    "Prec3 = np.zeros((NoSamples,1))\n",
    "Rec3 = np.zeros((NoSamples,1))\n",
    "Score3_A = np.zeros((NoSamples,1)) \n",
    "Prec3_A = np.zeros((NoSamples,1))\n",
    "Rec3_A = np.zeros((NoSamples,1))\n",
    "Score3_NA = np.zeros((NoSamples,1)) \n",
    "Prec3_NA = np.zeros((NoSamples,1))\n",
    "Rec3_NA = np.zeros((NoSamples,1))\n",
    "\n",
    "for i in range(0,NoSamples):\n",
    "    temp = getAccuracy(Xp,y,Xp2,y2)\n",
    "    Score1[i] = temp['Score1']\n",
    "    Prec1[i] = temp['Prec1']\n",
    "    Rec1[i] = temp['Rec1']\n",
    "    Score1_A[i] = temp['Score1_A']\n",
    "    Prec1_A[i] = temp['Prec1_A']\n",
    "    Rec1_A[i] = temp['Rec1_A']\n",
    "    Score1_NA[i] = temp['Score1_NA']\n",
    "    Prec1_NA[i] = temp['Prec1_NA']\n",
    "    Rec1_NA[i] = temp['Rec1_NA']\n",
    "    Score2[i] = temp['Score2']\n",
    "    Prec2[i] = temp['Prec2']\n",
    "    Rec2[i] = temp['Rec2']\n",
    "    Score3[i] = temp['Score3']\n",
    "    Prec3[i] = temp['Prec3']\n",
    "    Rec3[i] = temp['Rec3']\n",
    "    Score3_A[i] = temp['Score3_A']\n",
    "    Prec3_A[i] = temp['Prec3_A']\n",
    "    Rec3_A[i] = temp['Rec3_A']\n",
    "    Prec3_NA[i] = temp['Prec3_NA']\n",
    "    Rec3_NA[i] = temp['Rec3_NA']\n",
    "    Score3_NA[i] = temp['Score3_NA']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1 :{} 0.964236343367\n",
      "Precision 1 :{} 0.923662382996\n",
      "Recall 1 :{} 0.909058434056\n",
      "Score 2 :{} 0.952208088096\n",
      "Precision 2 :{} 0.88930188766\n",
      "Recall 2 :{} 0.887151007478\n",
      "Score 3 :{} 0.966153846154\n",
      "Precision 3 :{} 0.955100004626\n",
      "Recall 3 :{} 0.884108158783\n"
     ]
    }
   ],
   "source": [
    "print \"Score 1 :{}\", np.mean(Score1)\n",
    "print \"Precision 1 :{}\", np.mean(Prec1)\n",
    "print \"Recall 1 :{}\", np.mean(Rec1)\n",
    "print \"Score 2 :{}\", np.mean(Score2)\n",
    "print \"Precision 2 :{}\", np.mean(Prec2)\n",
    "print \"Recall 2 :{}\", np.mean(Rec2)\n",
    "print \"Score 3 :{}\", np.mean(Score3)\n",
    "print \"Precision 3 :{}\", np.mean(Prec3)\n",
    "print \"Recall 3 :{}\", np.mean(Rec3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1A :{} 0.854573324382\n",
      "Precision 1A :{} 0.826356700568\n",
      "Recall 1A :{} 0.819230678011\n",
      "Score 1 NA :{} 0.964236343367\n",
      "Precision 1 NA :{} 0.989228084405\n",
      "Recall 1 NA :{} 0.970133008246\n",
      "Score 3A :{} 0.862987172121\n",
      "Precision 3A :{} 0.897058400875\n",
      "Recall 3A :{} 0.755536193878\n",
      "Score 3 NA :{} 0.993332232321\n",
      "Precision 3 NA :{} 0.98885467141\n",
      "Recall 3 NA :{} 0.970133008246\n"
     ]
    }
   ],
   "source": [
    "print \"Score 1A :{}\", np.mean(Score1_A)\n",
    "print \"Precision 1A :{}\", np.mean(Prec1_A)\n",
    "print \"Recall 1A :{}\", np.mean(Rec1_A)\n",
    "\n",
    "print \"Score 1 NA :{}\", np.mean(Score1_NA)\n",
    "print \"Precision 1 NA :{}\", np.mean(Prec1_NA)\n",
    "print \"Recall 1 NA :{}\", np.mean(Rec1_NA)\n",
    "\n",
    "print \"Score 3A :{}\", np.mean(Score3_A)\n",
    "print \"Precision 3A :{}\", np.mean(Prec3_A)\n",
    "print \"Recall 3A :{}\", np.mean(Rec3_A)\n",
    "\n",
    "print \"Score 3 NA :{}\", np.mean(Score3_NA)\n",
    "print \"Precision 3 NA :{}\", np.mean(Prec3_NA)\n",
    "print \"Recall 3 NA :{}\", np.mean(Rec3_NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
